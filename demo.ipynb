{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "H6YAfJOzcf6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxY1nJJnZgOW"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "import pandas as pd\n",
        "\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "sys.path.append('/content/drive/Shareddrives/CMPE260/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vgyci241ZrqB",
        "outputId": "6c21a7c2-ae13-49a5-ae99-367463dc794d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run /content/drive/Shareddrives/CMPE260/code/rec_implementation.ipynb\n",
        "%run /content/drive/Shareddrives/CMPE260/code/rec_implementation_w_features.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2GHQ7dqaMDv",
        "outputId": "8e83ba65-57ee-4b81-8813-6a8f15e96164"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch_ranger\n",
            "  Downloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pytorch_ranger) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_ranger) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_ranger) (4.8.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_ranger) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_ranger) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_ranger) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_ranger) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_ranger) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pytorch_ranger) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->pytorch_ranger) (1.3.0)\n",
            "Installing collected packages: pytorch_ranger\n",
            "Successfully installed pytorch_ranger-0.1.1\n",
            "cpu\n",
            "Requirement already satisfied: pytorch_ranger in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pytorch_ranger) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_ranger) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_ranger) (4.8.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_ranger) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_ranger) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_ranger) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_ranger) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_ranger) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pytorch_ranger) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->pytorch_ranger) (1.3.0)\n",
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Demo"
      ],
      "metadata": {
        "id": "xiXqZonYdmAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_user_books(dummy_argument=None):\n",
        "  random_user = test_data['user'].sample().iloc[0]\n",
        "  temp_test_data = test_data[test_data.user == random_user]\n",
        "  temp_filtered = pd.merge(temp_test_data, filtered_df, on=['user', 'book'])\n",
        "  temp_filtered\n",
        "\n",
        "  features = user_features_df[user_features_df['user'] == random_user].iloc[0, 2:4]\n",
        "\n",
        "  temp_filtered['age'] = features[0]\n",
        "  temp_filtered['country'] = features[1]\n",
        "\n",
        "  books = temp_filtered['book'].sample(2)\n",
        "\n",
        "  book1 = temp_filtered[temp_filtered.book == books.iloc[0]]\n",
        "  book2 = temp_filtered[temp_filtered.book == books.iloc[1]]\n",
        "\n",
        "  user = f'User: {random_user}, Age: {book1.iloc[0, 8]}, Country: {book1.iloc[0, 9]}\\n'\n",
        "  book1_string = book1[['book', 'title', 'author']].to_string()+f'\\n'\n",
        "  book2_string = book2[['book', 'title', 'author']].to_string()+f'\\n'\n",
        "\n",
        "  # book1_string = f'Book 1: Id- {book1.iloc[0, 1]}, Title- {book1.iloc[0, 3]}, Author- {book1.iloc[0, 4]}\\n'\n",
        "  # book2_string = f'Book 2: Id- {book2.iloc[0, 1]}, Title- {book2.iloc[0, 3]}, Author- {book2.iloc[0, 4]}\\n',\n",
        "\n",
        "  input_2 = f'{book1.iloc[0, 1]}, {book2.iloc[0, 1]}'\n",
        "  results = generate_recommendations(input_2,random_user)\n",
        "\n",
        "  return user+book1_string+book2_string, results"
      ],
      "metadata": {
        "id": "xv7Sb_azg0bP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_model_with_features(model_dir, book1, book2, random_user):\n",
        "  recommendations = []\n",
        "\n",
        "  state_rep = State_Representation_w_Features(num_of_countries, num_of_age_buckets, num_of_books, params['embedding_dim'], params['hidden_dim'])\n",
        "  policy = Actor(params['embedding_dim'], params['hidden_dim'])\n",
        "  state_rep.load_state_dict(torch.load(params[model_dir] + 'best_state_repr.pth'))\n",
        "  policy.load_state_dict(torch.load(params[model_dir] + 'best_policy_net.pth'))\n",
        "\n",
        "  for model, state_representation in zip([policy], [state_rep]):\n",
        "    env = Environment_w_Features(test_matrix)\n",
        "    user, country, age, memory = env.reset(random_user)\n",
        "\n",
        "    # give 2 books that the user has rated in the past\n",
        "    user, memory, reward, _ = env.step(torch.tensor([book1]))\n",
        "    user, memory, reward, _ = env.step(torch.tensor([book2]))\n",
        "\n",
        "    # get next 3 recommendations based on the two books above\n",
        "    recs = []\n",
        "    for i in range(3):\n",
        "        action_emb = model(state_representation(country, age, memory))\n",
        "        action = model.get_action(\n",
        "            user,\n",
        "            torch.tensor(env.memory[user.detach().cpu().numpy().astype(int), :]),\n",
        "            state_representation,\n",
        "            action_emb,\n",
        "            torch.tensor([item for item in env.available_books if item not in env.viewed_books]).long()\n",
        "        )\n",
        "        user, memory, reward, _ = env.step(action)\n",
        "        recs.append(action)\n",
        "\n",
        "    recommendations.append(recs)\n",
        "\n",
        "    recos = [r.item() for r in recommendations[0]]\n",
        "    return recos"
      ],
      "metadata": {
        "id": "eTVyqc0aqD7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_model_vanilla(model_dir, book1, book2, random_user):\n",
        "  recommendations = []\n",
        "\n",
        "  state_rep = State_Representation(num_of_users, num_of_books, params['embedding_dim'], params['hidden_dim'])\n",
        "  policy = Actor(params['embedding_dim'], params['hidden_dim'])\n",
        "  state_rep.load_state_dict(torch.load(params[model_dir] + 'best_state_repr.pth'))\n",
        "  policy.load_state_dict(torch.load(params[model_dir] + 'best_policy_net.pth'))\n",
        "\n",
        "  for model, state_representation in zip([policy], [state_rep]):\n",
        "    env = Environment(test_matrix)\n",
        "    user, memory = env.reset(random_user)\n",
        "\n",
        "    # give 2 books that the user has rated in the past\n",
        "    user, memory, reward, _ = env.step(torch.tensor([book1]))\n",
        "    user, memory, reward, _ = env.step(torch.tensor([book2]))\n",
        "\n",
        "    # get next 3 recommendations based on the two books above\n",
        "    recs = []\n",
        "    for i in range(3):\n",
        "        action_emb = model(state_representation(user, memory))\n",
        "        action = model.get_action(\n",
        "            user,\n",
        "            torch.tensor(env.memory[user.detach().cpu().numpy().astype(int), :]),\n",
        "            state_representation,\n",
        "            action_emb,\n",
        "            torch.tensor([item for item in env.available_books if item not in env.viewed_books]).long()\n",
        "        )\n",
        "        user, memory, reward, _ = env.step(action)\n",
        "        recs.append(action)\n",
        "\n",
        "    recommendations.append(recs)\n",
        "\n",
        "    recos = [r.item() for r in recommendations[0]]\n",
        "    return recos"
      ],
      "metadata": {
        "id": "62iCpZJo0v0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_recommendations(books, random_user):\n",
        "  books = books.split(',')\n",
        "  book1 = int(books[0].strip())\n",
        "  book2 = int(books[1].strip())\n",
        "\n",
        "  model_dirs = ['log_w_features_dir']\n",
        "  methods = ['Vanilla with features']\n",
        "\n",
        "  vanilla_model_dirs = ['log_base_dir', 'log_w_ou_dir', 'log_w_gaussian_dir']\n",
        "  vanilla_methods = ['Vanilla', 'Vanilla with OU Noise', 'Vanilla with Gaussian Noise']\n",
        "\n",
        "  rec_string = \"\"\n",
        "\n",
        "  for d, m in zip(model_dirs, methods):\n",
        "    recs = run_model_with_features(d, book1, book2, random_user)\n",
        "    recommended_books = filtered_df[filtered_df.book.isin(recs)][['title', 'author', 'best_seller']].drop_duplicates()\n",
        "\n",
        "    rec_string = rec_string + m + \"\\n\"  + recommended_books.to_string() + \"\\n\\n\"\n",
        "\n",
        "  for d, m in zip(vanilla_model_dirs, vanilla_methods):\n",
        "    recs = run_model_vanilla(d, book1, book2, random_user)\n",
        "    recommended_books = filtered_df[filtered_df.book.isin(recs)][['title', 'author', 'best_seller']].drop_duplicates()\n",
        "\n",
        "    rec_string = rec_string + m + \"\\n\"  + recommended_books.to_string() + \"\\n\\n\"\n",
        "\n",
        "  return rec_string"
      ],
      "metadata": {
        "id": "XiV_lh8PxLtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_user = gr.Interface(\n",
        "    fn=generate_user_books,\n",
        "    inputs=gr.components.Button(value=\"Generate book history for a random user\"),\n",
        "    outputs=[\n",
        "        gr.components.Textbox(label = \"Book history of random user\",lines=10, placeholder=\"User book history will appear here...\"),\n",
        "        gr.components.Textbox(label=\"Recommended books\",lines=10, placeholder=\"Book recommendations\")\n",
        "    ],\n",
        "    title=\"Generate user book history\",\n",
        ")\n",
        "\n",
        "generate_user.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "_KwAcux7FlGL",
        "outputId": "aba6fe6b-a772-4fff-bdc1-431d1ad42dd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://d6106d509fca74dc20.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d6106d509fca74dc20.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://d6106d509fca74dc20.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VXyMsiKTuBtA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}