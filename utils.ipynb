{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"CqttWaelzhzj"},"outputs":[],"source":["import collections\n","import torch\n","import pandas as pd\n","import numpy as np\n","import random\n","import scipy.sparse as sp"]},{"cell_type":"markdown","source":["Reference: https://github.com/rail-berkeley/rlkit/tree/master/rlkit/exploration_strategies"],"metadata":{"id":"_L9sTF6wzqKW"}},{"cell_type":"code","source":["class GaussianStrategy():\n","  def __init__(self, max_sigma=1.0, min_sigma=None, decay_period=10):\n","    self._max_sigma = max_sigma\n","    if min_sigma is None:\n","        min_sigma = max_sigma\n","    self._min_sigma = min_sigma\n","    self._decay_period = decay_period\n","\n","  # add gaussian noise to action\n","  def get_action(self, action, t=None):\n","    sigma = (self._max_sigma - (self._max_sigma - self._min_sigma) * min(1.0, t * 1.0 / self._decay_period))\n","    return torch.Tensor([np.clip(action.detach().numpy() + np.random.normal(size=len(action)) * sigma, -1.0, 1.0)]).float()"],"metadata":{"id":"6k-jcGPFzjAy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class OUStrategy():\n","  def __init__(self, action_dim, mu=0.0, theta=0.15, max_sigma=0.4, min_sigma=0.4, decay_period=10):\n","    self.mu = mu\n","    self.theta = theta\n","    self.sigma = max_sigma\n","    self.max_sigma = max_sigma\n","    self.min_sigma = min_sigma\n","    self.decay_period = decay_period\n","    self.action_dim = action_dim\n","    self.reset()\n","\n","  def reset(self):\n","    self.state = np.ones(self.action_dim) * self.mu\n","\n","  def evolve_state(self):\n","    x  = self.state\n","    dx = self.theta * (self.mu - x) + self.sigma * np.random.randn(self.action_dim)\n","    self.state = x + dx\n","    return self.state\n","\n","  def get_action(self, action, t=0):\n","    ou_state = self.evolve_state()\n","    self.sigma = self.max_sigma - (self.max_sigma - self.min_sigma) * min(1.0, t / self.decay_period)\n","    return torch.tensor([action.detach().numpy() + ou_state]).float()"],"metadata":{"id":"WLX-HrSBztkG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Dataset(torch.utils.data.Dataset):\n","    def __init__(self, positive_interactions, num_of_books, interaction_matrix, negative_interactions=99):\n","      super(Dataset, self).__init__()\n","      self.positive_interactions = positive_interactions\n","      self.num_of_books = num_of_books\n","      self.interaction_matrix = interaction_matrix\n","      self.negative_interactions = negative_interactions\n","\n","      self.reset()\n","\n","    def reset(self):\n","      data = self.create_data()\n","      labels = np.zeros(len(self.positive_interactions) * (1 + self.negative_interactions))\n","      labels[::1+self.negative_interactions] = 1\n","      self.data = np.concatenate([np.array(data), np.array(labels)[:, np.newaxis]], axis=1)\n","\n","    def create_data(self):\n","      data = []\n","      for user, positive in self.positive_interactions:\n","        data.append([user, positive])\n","        for i in range(self.negative_interactions):\n","          negative = np.random.randint(self.num_of_books)\n","          # if user has rated the book, find another book which hasn't been rated by this user\n","          while (user, negative) in self.interaction_matrix:\n","              negative = np.random.randint(self.num_of_books)\n","          data.append([user, negative])\n","      return data\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","      user, book, label = self.data[idx]\n","      output = {'user': user, 'book': book, 'label': np.float32(label)}\n","\n","      return output"],"metadata":{"id":"9kJTrAZXzzf4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def filter_data(df):\n","    # filter for books that have a rating of 7 or higher (some users for these books will be lost since they rated it lower than 6)\n","    books_w_rating_gt_6 = df[df.rating > 6]\n","\n","    # take users who have rated 100-500 books and rating>6 due to RAM limitations\n","    grouped = books_w_rating_gt_6.groupby(['user_id'])['isbn'].count()\n","    user_ratings = grouped[(grouped>=100) & (grouped<=500)].index.tolist()\n","    filtered_df = books_w_rating_gt_6[books_w_rating_gt_6['user_id'].isin(user_ratings)]\n","\n","    # map user_id and isbn to contiguous values to avoid OOM issues\n","    filtered_df['user'] = pd.factorize(filtered_df['user_id'])[0] + 1\n","    filtered_df['book'] = pd.factorize(filtered_df['isbn'])[0] + 1\n","\n","    return filtered_df"],"metadata":{"id":"Gcxs1Hvwz3EC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preprocess_data(filtered_df):\n","    data = filtered_df[['user', 'book']]\n","\n","    num_of_users = data['user'].max() + 1\n","    num_of_books = data['book'].max() + 1\n","\n","    # train-test split\n","    train_data = data.sample(frac=0.9, random_state=101)\n","    test_data = data.drop(train_data.index)\n","\n","    # List of list [[user_id, isbn], [], [] ..]\n","    train_data_list = train_data.values.tolist()\n","    test_data_list = test_data.values.tolist()\n","\n","    train_mat = collections.defaultdict(int)\n","    test_mat = collections.defaultdict(int)\n","\n","    for user, book in train_data_list:\n","        train_mat[user, book] = 1.0\n","    for user, book in test_data_list:\n","        test_mat[user, book] = 1.0\n","\n","    # create sparse matrix for user-book interaction\n","    train_matrix = sp.dok_matrix((num_of_users, num_of_books), dtype=np.float16)\n","    dict.update(train_matrix, train_mat)\n","    test_matrix = sp.dok_matrix((num_of_users, num_of_books), dtype=np.float16)\n","    dict.update(test_matrix, test_mat)\n","\n","    # apt users are those who have rated 137-185 books\n","    apt_users = np.arange(num_of_users).reshape(-1, 1)[((train_matrix.sum(1) >= 137) & (train_matrix.sum(1) <= 185))]\n","\n","    return (train_data, train_matrix, test_data, test_matrix, num_of_users, num_of_books, apt_users)"],"metadata":{"id":"utTF3YWXz4is"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def process_user_features(user_features_df, filtered_df):\n","  # use required features only and map to user\n","  user_features_df = user_features_df[['user_id', 'age', 'country']]\n","  df = filtered_df[['user_id', 'user']].join(user_features_df.set_index('user_id'), how='left', on='user_id')\n","\n","  # Categorical Encoding for 'Country'\n","  unique_countries = df['country'].unique()\n","  num_of_countries = unique_countries.shape[0]\n","  mapping_country = {country: index for index, country in enumerate(unique_countries)}\n","  df['country_encoded'] = df['country'].map(mapping_country)\n","\n","  # Quantile-based bucketing for 'Age'\n","  num_of_age_buckets = 5  # Choose the desired number of age buckets\n","  df['age_encoded'] = pd.qcut(df['age'], q=num_of_age_buckets, labels=False, duplicates='drop')\n","\n","  return (df, num_of_countries, num_of_age_buckets)"],"metadata":{"id":"HRsdWCxx8eGC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_user_features(user, user_features_df):\n","  user_row = user_features_df[user_features_df['user'] == user].iloc[0]\n","  country = user_row.country_encoded\n","  age = user_row.age_encoded\n","\n","  return (country, age)"],"metadata":{"id":"jRIT8Y2G9Kvs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def hit_metric(recommended, actual, label, df):\n","  related_books = [a for idx, a in enumerate(actual) if label[idx]]\n","\n","  for rec in recommended:\n","    book = df[df.book == rec]\n","    if len(book) > 0:\n","      book = book.iloc[0]\n","      if book.best_seller:\n","        return True\n","    if rec in related_books:\n","      return True\n","\n","  return False\n","\n","def dcg_metric(recommended, actual, label, df):\n","  related_books = [a for idx, a in enumerate(actual) if label[idx]]\n","  flag = False\n","\n","  for rec in recommended:\n","    book = df[df.book == rec]\n","    if len(book) > 0:\n","      book = book.iloc[0]\n","      if book.best_seller:\n","        flag = True\n","\n","    if (rec in related_books) or flag:\n","      index = actual.index(rec)\n","      return np.reciprocal(np.log2(index + 2))\n","\n","  return 0"],"metadata":{"id":"eUkrPf-lz6Ne"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RIXpSBx2z7re"},"execution_count":null,"outputs":[]}]}